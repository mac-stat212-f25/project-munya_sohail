---
title: "SKM"
---


## Building and fitting ML Models to predict salary for data science postings
```{r}
# loading the necessary packages
library(tidyverse)
library(tidymodels)
library(VIM)
library(glmnet)

```

```{r}
# loading the cleaned/processed data
dsPostings_2025 <- read_csv("../data/processed/cleaned_data.csv")
dim(dsPostings_2025)
head(dsPostings_2025)

dsPostings_2025 |>
  countNA()# 699 na values


```

```{r}
# Imputing NA values to estimate NA Values -- Using KNN
# Tuning  K = 10 as choosing small K (2-5) follows local pattern and can be overfit (high variance, low biad) and
# choosing large K (30+) oversmoothens leading to underfitting which is high bias and low variance
dsPostings_2025
imputed_df <- kNN(dsPostings_2025, k = 10)

imputed_df<- imputed_df |>
  select(job_title, seniority_level, status, location, post_date, industry, ownership, company_size, revenue, avg_salary_usd, skills)

#imputed_df

#view(imputed_df)




```

### Model Buildinhg
```{r}
# Step 1. Implementing the Lasso algorithm to penalize predictors which might add complexity
lasso_spec <- linear_reg() %>%
set_mode("regression") %>%
set_engine("glmnet") %>%
set_args(mixture = 1, penalty = tune())

reg_spec <- linear_reg() %>%
set_mode("regression") %>%
set_engine("glmnet")






# Step 2. Variable recipe
variable_recipe <- recipe(avg_salary_usd ~ ., data = imputed_df) %>%
  step_novel(all_nominal_predictors()) %>%        # handle unseen levels
  step_dummy(all_nominal_predictors()) %>%        # create dummies (including *_new)
  step_zv(all_predictors()) %>%                   # drop any zero-variance columns
  step_normalize(all_numeric_predictors())        # then scale



# Variable recipe for regression
variable_rec<-recipe(avg_salary_usd ~ .,data= imputed_df)


# STEP 3: workflow specification (model + recipe)
lasso_workflow <- workflow() %>%
add_recipe(variable_recipe) %>%
add_model(lasso_spec)

reg_workflow <- workflow() |>
  add_recipe(variable_rec) |>
  add_model(reg_spec)

# STEP 4:Estimate 20 Models w/10 folds each using Cross Validation Algorithm
set.seed(212)
lasso_models <- lasso_workflow %>%
tune_grid(
grid = grid_regular(penalty(range = c(-5, 1)), levels = 10),
resamples = vfold_cv(imputed_df, v = 10),
metrics = metric_set(mae)
)


```

```{r}
autoplot(lasso_models) +
scale_x_continuous() +
xlab(expression(lambda)) # Shows on linear pattern as mae stays constant as we tune the parameter
```
```{r}

# Data Prep and splits
set.seed(212)

salary_df <- imputed_df |>
  mutate(
    across(c(job_title, seniority_level, status, location,
             industry, ownership, company_size, revenue, skills),
           as.factor)
  )

data_split  <- initial_split(salary_df, prop = 0.8, strata = avg_salary_usd)
train_data  <- training(data_split)
test_data   <- testing(data_split)


# recipe and model specification
salary_recipe <- recipe(avg_salary_usd ~ ., data = train_data) |>
  step_novel(all_nominal_predictors()) |>        # handle unseen levels
  step_dummy(all_nominal_predictors()) |>        # create dummies
  step_zv(all_predictors()) |>                   # drop zero-variance columns
  step_normalize(all_numeric_predictors())

rf_spec <- rand_forest(
  mtry  = tune(),
  trees = 500,
  min_n = tune()
) |>
  set_mode("regression") |>
  set_engine("ranger", importance = "impurity")

```

```{r}
# Workflow, tuning, and evaluation
rf_workflow <- workflow() |>
  add_model(rf_spec) |>
  add_recipe(salary_recipe)

set.seed(253)
rf_grid <- grid_regular(
  mtry(range = c(3, 20)),
  min_n(range = c(2, 20)),
  levels = 5
)

set.seed(253)
cv_folds <- vfold_cv(train_data, v = 5, strata = avg_salary_usd)

rf_tuned <- tune_grid(
  rf_workflow,
  resamples = cv_folds,
  grid = rf_grid,
  metrics = metric_set(mae, rmse, rsq)
)

show_best(rf_tuned, metric = "mae")
best_rf <- select_best(rf_tuned, metric = "mae")

final_rf <- finalize_workflow(rf_workflow, best_rf) |>
  fit(data = train_data)

salary_metrics <- final_rf |>
  predict(test_data) |>
  bind_cols(test_data) |>
  metrics(truth = avg_salary_usd, estimate = .pred)

salary_metrics

```


```{r}
autoplot(rf_tuned, metric = "mae") # reasonable baseline: tuning changed MAE by ~10k across the full mtry range, so the model is learning something, but the remaining error is still very high, which points more to limited or noisy features than to the wrong algorithm.
```

```{r}
# Fitting Linear Reg'


# STEP 1: specify the type of model to build
lm_spec <- linear_reg() %>% # we want a linear regression model
  set_mode("regression") %>%  # this is a regression task (y is quantitative)
  set_engine("lm") # we'll estimate the model using the lm function

# STEP 2: estimate the specified model using sample data
model_estimate <- lm_spec %>%
  fit(avg_salary_usd ~.,   data = imputed_df )

# Get the model coefficients
model_estimate %>%
  tidy()


model_estimate %>%
  augment(new_data = imputed_df)




```

```{r}
model_estimate %>%
  glance() #
```

